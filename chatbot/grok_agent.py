# chatbot/grok_agent.py
from __future__ import annotations
import os, json, re
from typing import Any, Dict, List
from xai_sdk import Client
from xai_sdk.chat import system, user

GROK_MODEL = os.getenv("GROK_MODEL", "grok-4")

# =========================
# üìö Glosario y sin√≥nimos
# =========================
# Mapea columnas del NASA Exoplanet Archive (TESS) a las features usadas en el pipeline y sin√≥nimos comunes.
VAR_GLOSSARY = {
    # --- Planeta / tr√°nsito ---
    "orbital_period": {
        "aliases": ["period", "periodo", "per√≠odo", "pl_orbper", "days", "d√≠as"],
        "from_table": "pl_orbper",
        "unit": "d√≠as",
        "explain": "Tiempo que tarda el planeta en completar una √≥rbita. En tr√°nsitos, periodos cortos generan m√°s eventos observables."
    },
    "duration_hours": {
        "aliases": ["duration", "duraci√≥n", "pl_trandurh", "hours", "horas"],
        "from_table": "pl_trandurh",
        "unit": "horas",
        "explain": "Duraci√≥n del tr√°nsito (inicio a fin). Tr√°nsitos muy cortos o muy largos pueden indicar geometr√≠as o contaminaciones at√≠picas."
    },
    "depth_ppm": {
        "aliases": ["depth", "profundidad", "trandept", "pl_trandep", "ppm"],
        "from_table": "pl_trandep",
        "unit": "ppm",
        "explain": "Cu√°nto se aten√∫a la luz de la estrella durante el tr√°nsito. Profundidades m√°s altas suelen indicar planetas m√°s grandes o blends."
    },
    "radius_re": {
        "aliases": ["radius", "radio", "pl_rade", "re", "r_earth"],
        "from_table": "pl_rade",
        "unit": "R‚äï",
        "explain": "Radio del planeta en radios-Tierra. Depende de la profundidad y del radio estelar asumido."
    },
    "insol": {
        "aliases": ["insolation", "irradiance", "pl_insol", "flux"],
        "from_table": "pl_insol",
        "unit": "F‚äï",
        "explain": "Flujo incidente relativo a la Tierra; aproxima qu√© tanta energ√≠a recibe el planeta."
    },
    # --- Estrella ---
    "teff": {
        "aliases": ["teff", "temperatura", "st_teff", "effective temperature"],
        "from_table": "st_teff",
        "unit": "K",
        "explain": "Temperatura efectiva de la estrella. Afecta la profundidad esperada y el c√°lculo de insolaci√≥n."
    },
    "star_rad_rs": {
        "aliases": ["stellar radius", "st_rad", "radio estelar", "rs", "r_sun"],
        "from_table": "st_rad",
        "unit": "R‚òâ",
        "explain": "Radio de la estrella. Clave para convertir profundidad de tr√°nsito a radio planetario."
    },
    "mag": {
        "aliases": ["tess mag", "st_tmag", "magnitud", "tmagtess"],
        "from_table": "st_tmag",
        "unit": "mag (TESS)",
        "explain": "Magnitud en banda TESS; afecta SNR y detectabilidad."
    },
    # --- Se√±al ---
    "snr": {
        "aliases": ["s/n", "signal to noise", "relaci√≥n se√±al ruido", "snr"],
        "from_table": None,  # puede no venir directo en TOI; si existe en tu DF, se usar√° tal cual
        "unit": "adimensional",
        "explain": "Relaci√≥n se√±al-ruido del tr√°nsito. M√°s alto, m√°s confiable (ojo a outliers por systematics)."
    },
}

# Mapa inverso de sin√≥nimos ‚Üí key est√°ndar
ALIAS2KEY: Dict[str, str] = {}
for k, meta in VAR_GLOSSARY.items():
    ALIAS2KEY[k.lower()] = k
    for a in meta["aliases"]:
        ALIAS2KEY[a.lower()] = k

# =========================
# üß≠ Sistema conversacional
# =========================
SYSTEM_PROMPT = """Eres un copiloto astrof√≠sico en espa√±ol, amable y claro.
Puedes saludar, guiar al usuario por la plataforma, explicar variables (con sin√≥nimos) y resumir resultados.
NO uses jerga innecesaria. Mant√©n un tono cercano y pedag√≥gico.

SIEMPRE devuelve **UN JSON V√ÅLIDO** con esta forma:

{
  "action": "<NONE|EXPLAIN_CASE|QUERY_DF|PLOT|METRICS>",
  "args": { },
  "narrative": {
    "tldr": "resumen breve (1-2 frases)",
    "class": "CONFIRMED|CANDIDATE|FALSE POSITIVE|UNKNOWN",
    "confidence": "alto|medio|bajo",
    "details": ["bullets (3‚Äì6 m√°x)"],
    "risks": ["limitaciones o sesgos relevantes"],
    "next_steps": ["siguientes acciones o vistas a usar"]
  },
  "viz_suggestions": {
    "plots": [{"kind":"scatter2d","x":"radius_re","y":"depth_ppm"}],
    "filters": [{"column":"mission","op":"in","value":["TESS"]}],
    "notes": "Evita azules oscuros para puntos; usa alto contraste."
  }
}

REGLAS:
- Usa SOLO columnas reales del contexto (features/columns).
- Si el usuario saluda o pide ayuda/explique la plataforma ‚Üí action="NONE", responde con narrativa y tips.
- Si pregunta ‚Äú¬øqu√© significa X?‚Äù o ‚Äúexplica la variable Y?‚Äù ‚Üí incluye explicaci√≥n breve (usa 'details').
- Si pide interpretar resultados globales y hay pred_summary/metric_summary ‚Üí usa eso, sin llamar tools.
- Si pide un caso concreto ‚Üí action="EXPLAIN_CASE" (args con source_id si se deduce).
- Si pide m√©tricas ‚Üí action="METRICS".
- Si pide filas con filtros ‚Üí "QUERY_DF".
- Si pide un gr√°fico ‚Üí "PLOT" con {x,y,(z opcional)}.
- Mant√©n ‚Äútldr‚Äù conciso; 3‚Äì6 bullets en ‚Äúdetails‚Äù; evita p√°rrafos largos.
- No inventes columnas: valida con 'columns' y 'features_*' del contexto.
- Evita usar azul oscuro para puntos (se mezcla con el tema de fondo).
"""

ALLOWED_ACTIONS = {"NONE","EXPLAIN_CASE","QUERY_DF","PLOT","METRICS"}

def _coerce_json(s: str) -> Dict[str, Any]:
    """Extrae JSON aunque venga envuelto en texto/c√≥digo; fallback a narrativa simple."""
    try:
        start = s.find("{"); end = s.rfind("}")
        if start != -1 and end != -1 and end > start:
            return json.loads(s[start:end+1])
    except Exception:
        pass
    try:
        blocks = re.findall(r"```(?:json)?\s*(\{.*?\})\s*```", s, flags=re.S|re.I)
        for b in blocks:
            try: return json.loads(b)
            except Exception: continue
    except Exception:
        pass
    t = (s or "").strip().replace("\n"," ")
    if len(t) > 400: t = t[:400] + "‚Ä¶"
    return {
        "action":"NONE","args":{},
        "narrative":{
            "tldr": t or "Hola, ¬øen qu√© te ayudo? Puedo explicar las variables, guiarte por la app o interpretar resultados.",
            "class":"UNKNOWN","confidence":"bajo","details":[],"risks":[],"next_steps":[]
        },
        "viz_suggestions":{"plots":[],"filters":[],"notes":""}
    }

def _sanitize(d: Dict[str, Any]) -> Dict[str, Any]:
    if not isinstance(d, dict): d = {}
    action = str(d.get("action","NONE")).upper()
    if action not in ALLOWED_ACTIONS: action = "NONE"
    args = d.get("args") or {}
    if not isinstance(args, dict): args = {}
    nar = d.get("narrative") or {}
    if not isinstance(nar, dict): nar = {}
    nar.setdefault("tldr","")
    nar.setdefault("class","UNKNOWN")
    nar.setdefault("confidence","bajo")
    for k in ("details","risks","next_steps"):
        v = nar.get(k, [])
        nar[k] = [str(x) for x in (v if isinstance(v, list) else [])][:6]
    viz = d.get("viz_suggestions") or {}
    if not isinstance(viz, dict): viz = {}
    viz.setdefault("plots", []); viz.setdefault("filters", []); viz.setdefault("notes", "")
    return {"action":action,"args":args,"narrative":nar,"viz_suggestions":viz}

def _best_var_key(query: str, available: List[str]) -> str | None:
    """Encuentra la variable pedida por el usuario usando sin√≥nimos y valida que exista en el DF."""
    q = (query or "").lower()
    # Busca por alias
    for token in re.findall(r"[a-zA-Z_]+", q):
        key = ALIAS2KEY.get(token.lower())
        if key and (key in available):
            return key
    # match directo por contains con columnas disponibles
    for col in available:
        if col.lower() in q:
            return col
    return None

def _fill_defaults(payload: Dict[str, Any], ctx: Dict[str, Any]) -> Dict[str, Any]:
    if not ctx: return payload
    cols = ctx.get("columns") or []
    feats = (ctx.get("features_num") or []) + (ctx.get("features_cat") or [])
    valid = set(cols) | set(feats)
    a = payload.get("action")
    args = payload.get("args", {})

    # Autocompletar PLOT x/y
    if a == "PLOT":
        x = args.get("x"); y = args.get("y")
        if not x or x not in valid:
            args["x"] = next((f for f in ctx.get("features_num", []) if f in valid), next(iter(valid), "radius_re"))
        if not y or y not in valid or y == args["x"]:
            y_cand = [f for f in ctx.get("features_num", []) if f != args["x"] and f in valid]
            args["y"] = y_cand[0] if y_cand else "orbital_period"
        payload["args"] = args

    # Limitar QUERY_DF
    if a == "QUERY_DF":
        try: lim = int(args.get("limit", 20))
        except Exception: lim = 20
        args["limit"] = max(1, min(lim, 200))
        payload["args"] = args

    # Sugerencias por defecto si no hay acci√≥n
    if a == "NONE":
        viz = payload.get("viz_suggestions", {})
        if isinstance(viz, dict) and not viz.get("plots"):
            basic = []
            feats_num = ctx.get("features_num", [])
            if len(feats_num) >= 2:
                basic.append({"kind":"scatter2d","x":feats_num[0],"y":feats_num[1]})
            if len(feats_num) >= 3:
                basic.append({"kind":"scatter3d","x":feats_num[0],"y":feats_num[1],"z":feats_num[2]})
            viz["plots"] = basic
            viz["notes"] = (viz.get("notes","") + " Evita azules oscuros; usa alto contraste.").strip()
            payload["viz_suggestions"] = viz
    return payload

def _compose_help_narrative(ctx: Dict[str, Any]) -> Dict[str, Any]:
    """Respuesta amable de onboarding/ayuda general."""
    has_model = ctx.get("has_model", False)
    details = [
        "Exploro candidatos TESS y predigo: **CONFIRMED**, **CANDIDATE** o **FALSE POSITIVE**.",
        "Gr√°ficas recomendadas: 2D `radius_re` vs `depth_ppm` y 3D con `orbital_period`/`duration_hours`.",
        "P√≠deme: *'¬øqu√© significa depth?'*, *'explica teff'*, *'m√©tricas del modelo'*, o *'grafica radius vs period'*.",
    ]
    if has_model:
        details.append("Tu modelo ya est√° entrenado: puedo interpretar probabilidades y casos concretos (EXPLAIN_CASE).")
    else:
        details.append("A√∫n no hay modelo entrenado: ve a **üß† Entrenar modelo (TESS)** y pulsa *Entrenar ahora*.")
    return {
        "tldr": "¬°Hola! Soy tu copiloto astrof√≠sico. Te explico variables, gr√°ficos y resultados, y te gu√≠o por la app.",
        "class": "UNKNOWN",
        "confidence": "alto",
        "details": details[:6],
        "risks": ["Las predicciones dependen de la calidad de datos y balance de clases."],
        "next_steps": ["Abre 'Predicci√≥n r√°pida (TESS)' para ver distribuciones", "P√≠deme un gr√°fico o una explicaci√≥n de variable"]
    }

def _compose_var_narrative(var_key: str, ctx: Dict[str, Any]) -> Dict[str, Any]:
    meta = VAR_GLOSSARY.get(var_key, {})
    label = var_key
    unit = meta.get("unit", "")
    from_table = meta.get("from_table", "")
    expl = meta.get("explain", "Variable del cat√°logo.")
    bullets = [
        f"**Nombre:** `{label}`  ‚Ä¢ **TOI column:** `{from_table or label}`  ‚Ä¢ **Unidad:** {unit or '‚Äî'}",
        f"**Qu√© es:** {expl}",
        "Impacto en la predicci√≥n: el modelo aprende patrones multivariados; por s√≠ sola no decide la clase.",
    ]
    bullets.append("Tip de gr√°fica: usa un *scatter* con color por clase; evita azules oscuros para puntos.")
    return {
        "tldr": f"`{label}`: {expl}",
        "class": "UNKNOWN",
        "confidence": "alto",
        "details": bullets[:6],
        "risks": ["Cuidado con valores extremos y unidades/escala; revisa outliers."],
        "next_steps": [f"Grafica `{label}` vs `depth_ppm` o `orbital_period`", "Consulta histogramas de probabilidades"]
    }

def _compose_pipeline_narrative(ctx: Dict[str, Any]) -> Dict[str, Any]:
    bullets = [
        "Preprocesamiento: **StandardScaler** en num√©ricos y **OneHotEncoder** para `mission`.",
        "Modelo: **XGBoost** multiclase calibrado con **isotonic** (`CalibratedClassifierCV cv=3`).",
        "Entrenamiento: *stratified split* (o test externo si hubiera varias misiones).",
        "M√©tricas: reporte de clasificaci√≥n, matriz de confusi√≥n y **AUC OvR (macro)**.",
        "Predicci√≥n: `predict_proba` ‚Üí probabilidades por clase; salida principal = clase con mayor prob.",
    ]
    return {
        "tldr": "El pipeline estandariza/one-hot, entrena XGBoost multiclase y calibra probabilidades.",
        "class": "UNKNOWN",
        "confidence": "alto",
        "details": bullets[:6],
        "risks": ["Desbalance de clases puede afectar F1; calibra y revisa matriz de confusi√≥n."],
        "next_steps": ["Mira 'üß† Entrenar modelo (TESS)' y luego 'üîÆ Predicci√≥n r√°pida (TESS)'"]
    }

class GrokAgent:
    def __init__(self, api_key: str | None = None, model: str = GROK_MODEL, timeout: int = 120, temperature: float = 0.2):
        api_key = api_key or os.getenv("XAI_API_KEY")
        if not api_key:
            raise RuntimeError("Falta XAI_API_KEY en entorno.")
        self.client = Client(api_key=api_key, timeout=timeout)
        self.chat = self.client.chat.create(model=model, temperature=temperature)
        self.chat.append(system(SYSTEM_PROMPT))

    def run(self, user_text: str, context_hint: dict | None = None) -> dict:
        ctx = context_hint or {}
        # ---- Detecci√≥n simple de intenci√≥n para respuestas naturales (sin llamar tools)
        text = (user_text or "").strip().lower()
        columns = [c.lower() for c in (ctx.get("columns") or [])]
        features = [c.lower() for c in (ctx.get("features_num") or []) + (ctx.get("features_cat") or [])]
        available = list(set(columns) | set(features))

        # ¬øSaludo/ayuda?
        if re.search(r"\b(hola|buenas|qu√© onda|ayuda|help|c√≥mo uso|como uso|gu√≠a|guiame|gu√≠ame)\b", text):
            payload = {
                "action": "NONE",
                "args": {},
                "narrative": _compose_help_narrative(ctx),
                "viz_suggestions": {
                    "plots": [{"kind":"scatter2d","x":"radius_re","y":"depth_ppm"}],
                    "filters": [{"column":"mission","op":"in","value":["TESS"]}],
                    "notes": "Evita azules oscuros para puntos; usa alto contraste."
                }
            }
            return _sanitize(payload)

        # ¬øPregunta de variable? (qu√© es, que significa, explica X)
        if re.search(r"(qu√©\s+es|que\s+es|qu√©\s+significa|que\s+significa|explica|definici√≥n de)\s+", text):
            key = _best_var_key(text, available)
            if key:
                payload = {
                    "action": "NONE",
                    "args": {},
                    "narrative": _compose_var_narrative(key, ctx),
                    "viz_suggestions": {
                        "plots": [{"kind":"scatter2d","x":key,"y":"depth_ppm"}],
                        "filters": [{"column":"mission","op":"in","value":["TESS"]}],
                        "notes": "Evita azules oscuros; prioriza contraste."
                    }
                }
                return _sanitize(payload)

        # ¬øPipeline / c√≥mo funciona / objetivo?
        if re.search(r"(pipeline|c√≥mo funciona|como funciona|objetivo|qu√© predice|que predice|modelo)\b", text):
            payload = {
                "action": "NONE",
                "args": {},
                "narrative": _compose_pipeline_narrative(ctx),
                "viz_suggestions": {
                    "plots": [{"kind":"scatter3d","x":"radius_re","y":"orbital_period","z":"duration_hours"}],
                    "filters": [{"column":"mission","op":"in","value":["TESS"]}],
                    "notes": "Usa alto contraste en puntos; a√±ade hover con `source_id`."
                }
            }
            return _sanitize(payload)

        # Si no hay una intenci√≥n ‚Äúcharla/ayuda‚Äù detectada, mandamos al modelo LLM con contexto compacto
        compact_ctx = {
            "has_model": bool(ctx.get("has_model")),
            "columns": list(ctx.get("columns", []))[:100],
            "features_num": list(ctx.get("features_num", []))[:50],
            "features_cat": list(ctx.get("features_cat", []))[:50],
            "classes": list(ctx.get("classes", []))[:20],
            "pred_summary": ctx.get("pred_summary", {}),
            "metric_summary": ctx.get("metric_summary", {}),
            "style_notes": "Fondo azul medio; evita puntos azul oscuro."
        }

        prompt = f"{user_text.strip()}\n\n[contexto]\n{json.dumps(compact_ctx, ensure_ascii=False)}"
        self.chat.append(user(prompt))
        resp = self.chat.sample()
        raw = _coerce_json(getattr(resp, "content", str(resp)) or "")
        clean = _sanitize(raw)
        final = _fill_defaults(clean, compact_ctx)
        return final
